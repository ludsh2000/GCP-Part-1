{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "be1cc59f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=a1uGXYqTmcMEIxISeiEq4FWGV1bLBO&access_type=offline&code_challenge=F5oB2lw4R4Eq9g4vsCQbasvnhbpfPY_6d8QQJsJwfug&code_challenge_method=S256\n",
      "\n",
      "\n",
      "You are now logged in as [me.mrhimanshu@gmail.com].\n",
      "Your current project is [pipelinetest-321606].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"pipelinetest-321606\"\n",
    "REGION = \"us-central1\" #though us-central is cheaper\n",
    "PIPELINE_ROOT = \"gs://pipelinetest_testing/pipeline_root\"\n",
    "!gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7af42e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID: pipelinetest-321606\n",
      "NAME: pipelinetest\n",
      "PROJECT_NUMBER: 217459805283\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30620644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project pipelinetest-321606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e7d71719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=PIPELINE_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "421e2d87",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gcloud\n",
      "  Downloading gcloud-0.18.3.tar.gz (454 kB)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in c:\\users\\hsain\\.conda\\envs\\testenv\\lib\\site-packages (from gcloud) (0.19.1)\n",
      "Requirement already satisfied: googleapis-common-protos in c:\\users\\hsain\\.conda\\envs\\testenv\\lib\\site-packages (from gcloud) (1.53.0)\n",
      "Collecting oauth2client>=2.0.1\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in c:\\users\\hsain\\.conda\\envs\\testenv\\lib\\site-packages (from gcloud) (3.17.1)\n",
      "Requirement already satisfied: six in c:\\users\\hsain\\.conda\\envs\\testenv\\lib\\site-packages (from gcloud) (1.16.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in c:\\users\\hsain\\.conda\\envs\\testenv\\lib\\site-packages (from httplib2>=0.9.1->gcloud) (2.4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in c:\\users\\hsain\\.conda\\envs\\testenv\\lib\\site-packages (from oauth2client>=2.0.1->gcloud) (0.2.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in c:\\users\\hsain\\.conda\\envs\\testenv\\lib\\site-packages (from oauth2client>=2.0.1->gcloud) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in c:\\users\\hsain\\.conda\\envs\\testenv\\lib\\site-packages (from oauth2client>=2.0.1->gcloud) (4.7.2)\n",
      "Building wheels for collected packages: gcloud\n",
      "  Building wheel for gcloud (setup.py): started\n",
      "  Building wheel for gcloud (setup.py): finished with status 'done'\n",
      "  Created wheel for gcloud: filename=gcloud-0.18.3-py3-none-any.whl size=602937 sha256=e21ea20a66fa62204960254bec9b012db0130d208538e71a0e629bee60a785ec\n",
      "  Stored in directory: c:\\users\\hsain\\appdata\\local\\pip\\cache\\wheels\\86\\05\\94\\4ad6324debd4e3edba7fdf252f1ff2d2aba09673a794e67a27\n",
      "Successfully built gcloud\n",
      "Installing collected packages: oauth2client, gcloud\n",
      "Successfully installed gcloud-0.18.3 oauth2client-4.1.3\n"
     ]
    }
   ],
   "source": [
    "#!pip install kfp --upgrade\n",
    "#!pip install --upgrade google-cloud-storage\n",
    "#!pip3 install google-cloud-aiplatform --upgrade\n",
    "#!pip3 install kfp google-cloud-pipeline-components --upgrade\n",
    "#!pip install --upgrade gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "46feed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        ClassificationMetrics,\n",
    "                        component)\n",
    "\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.google import experimental\n",
    "from kfp.v2.google.client import AIPlatformClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2881281a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=C:\\Users\\hsain\\.conda\\envs\\testenv;C:\\Users\\hsain\\.conda\\envs\\testenv\\Library\\mingw-w64\\bin;C:\\Users\\hsain\\.conda\\envs\\testenv\\Library\\usr\\bin;C:\\Users\\hsain\\.conda\\envs\\testenv\\Library\\bin;C:\\Users\\hsain\\.conda\\envs\\testenv\\Scripts;C:\\Users\\hsain\\.conda\\envs\\testenv\\bin;C:\\ProgramData\\Anaconda3\\condabin;C:\\Program Files (x86)\\Common Files\\Intel\\Shared Libraries\\redist\\intel64\\compiler;C:\\cuda\\bin;C:\\cuda\\include;C:\\cuda\\lib\\x64;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.3\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.3\\libnvvp;C:\\ProgramData\\Anaconda3;C:\\ProgramData\\Anaconda3\\Library\\mingw-w64\\bin;C:\\ProgramData\\Anaconda3\\Library\\usr\\bin;C:\\ProgramData\\Anaconda3\\Library\\bin;C:\\ProgramData\\Anaconda3\\Scripts;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0;C:\\WINDOWS\\System32\\OpenSSH;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\Nsight Compute 2021.1.1;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.3\\extras\\CUPTI\\lib64;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.3\\include;C:\\Program Files (x86)\\Minimal ADB and Fastboot;C:\\Program Files (x86)\\Google\\Cloud SDK\\google-cloud-sdk\\bin;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0;C:\\WINDOWS\\System32\\OpenSSH;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\ProgramData\\DockerDesktop\\version-bin;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\Users\\hsain\\AppData\\Local\\Microsoft\\WindowsApps;.;C:\\Users\\hsain\\AppData\\Local\\Programs\\Microsoft VS Code\\bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin\n"
     ]
    }
   ],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2ca10ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest\",\n",
    "    output_component_file=\"tables_eval_component.yaml\", # Optional: you can use this to load the component later\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    ")\n",
    "def classif_model_eval_metrics(\n",
    "    project: str,\n",
    "    location: str,  # \"us-central1\",\n",
    "    api_endpoint: str,  # \"us-central1-aiplatform.googleapis.com\",\n",
    "    thresholds_dict_str: str,\n",
    "    model: Input[Model],\n",
    "    metrics: Output[Metrics],\n",
    "    metricsc: Output[ClassificationMetrics],\n",
    ") -> NamedTuple(\"Outputs\", [(\"dep_decision\", str)]):  # Return parameter.\n",
    "\n",
    "    import json\n",
    "    import logging\n",
    "\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    # Fetch model eval info\n",
    "    def get_eval_info(client, model_name):\n",
    "        from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "        response = client.list_model_evaluations(parent=model_name)\n",
    "        metrics_list = []\n",
    "        metrics_string_list = []\n",
    "        for evaluation in response:\n",
    "            print(\"model_evaluation\")\n",
    "            print(\" name:\", evaluation.name)\n",
    "            print(\" metrics_schema_uri:\", evaluation.metrics_schema_uri)\n",
    "            metrics = MessageToDict(evaluation._pb.metrics)\n",
    "            for metric in metrics.keys():\n",
    "                logging.info(\"metric: %s, value: %s\", metric, metrics[metric])\n",
    "            metrics_str = json.dumps(metrics)\n",
    "            metrics_list.append(metrics)\n",
    "            metrics_string_list.append(metrics_str)\n",
    "\n",
    "        return (\n",
    "            evaluation.name,\n",
    "            metrics_list,\n",
    "            metrics_string_list,\n",
    "        )\n",
    "\n",
    "    # Use the given metrics threshold(s) to determine whether the model is \n",
    "    # accurate enough to deploy.\n",
    "    def classification_thresholds_check(metrics_dict, thresholds_dict):\n",
    "        for k, v in thresholds_dict.items():\n",
    "            logging.info(\"k {}, v {}\".format(k, v))\n",
    "            if k in [\"auRoc\", \"auPrc\"]:  # higher is better\n",
    "                if metrics_dict[k] < v:  # if under threshold, don't deploy\n",
    "                    logging.info(\n",
    "                        \"{} < {}; returning False\".format(metrics_dict[k], v)\n",
    "                    )\n",
    "                    return False\n",
    "        logging.info(\"threshold checks passed.\")\n",
    "        return True\n",
    "\n",
    "    def log_metrics(metrics_list, metricsc):\n",
    "        test_confusion_matrix = metrics_list[0][\"confusionMatrix\"]\n",
    "        logging.info(\"rows: %s\", test_confusion_matrix[\"rows\"])\n",
    "\n",
    "        # log the ROC curve\n",
    "        fpr = []\n",
    "        tpr = []\n",
    "        thresholds = []\n",
    "        for item in metrics_list[0][\"confidenceMetrics\"]:\n",
    "            fpr.append(item.get(\"falsePositiveRate\", 0.0))\n",
    "            tpr.append(item.get(\"recall\", 0.0))\n",
    "            thresholds.append(item.get(\"confidenceThreshold\", 0.0))\n",
    "        print(f\"fpr: {fpr}\")\n",
    "        print(f\"tpr: {tpr}\")\n",
    "        print(f\"thresholds: {thresholds}\")\n",
    "        metricsc.log_roc_curve(fpr, tpr, thresholds)\n",
    "\n",
    "        # log the confusion matrix\n",
    "        annotations = []\n",
    "        for item in test_confusion_matrix[\"annotationSpecs\"]:\n",
    "            annotations.append(item[\"displayName\"])\n",
    "        logging.info(\"confusion matrix annotations: %s\", annotations)\n",
    "        metricsc.log_confusion_matrix(\n",
    "            annotations,\n",
    "            test_confusion_matrix[\"rows\"],\n",
    "        )\n",
    "\n",
    "        # log textual metrics info as well\n",
    "        for metric in metrics_list[0].keys():\n",
    "            if metric != \"confidenceMetrics\":\n",
    "                val_string = json.dumps(metrics_list[0][metric])\n",
    "                metrics.log_metric(metric, val_string)\n",
    "        # metrics.metadata[\"model_type\"] = \"AutoML Tabular classification\"\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    aiplatform.init(project=project)\n",
    "    # extract the model resource name from the input Model Artifact\n",
    "    model_resource_path = model.uri.replace(\"aiplatform://v1/\", \"\")\n",
    "    logging.info(\"model path: %s\", model_resource_path)\n",
    "\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\n",
    "    eval_name, metrics_list, metrics_str_list = get_eval_info(\n",
    "        client, model_resource_path\n",
    "    )\n",
    "    logging.info(\"got evaluation name: %s\", eval_name)\n",
    "    logging.info(\"got metrics list: %s\", metrics_list)\n",
    "    log_metrics(metrics_list, metricsc)\n",
    "\n",
    "    thresholds_dict = json.loads(thresholds_dict_str)\n",
    "    deploy = classification_thresholds_check(metrics_list[0], thresholds_dict)\n",
    "    if deploy:\n",
    "        dep_decision = \"true\"\n",
    "    else:\n",
    "        dep_decision = \"false\"\n",
    "    logging.info(\"deployment decision is %s\", dep_decision)\n",
    "\n",
    "    return (dep_decision,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e016149-1fd2-46be-99a2-be96afd08213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "25fd1608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl-beans1627896209\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "DISPLAY_NAME = 'automl-beans{}'.format(str(int(time.time())))\n",
    "print(DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "357945bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"pipeline-test-1\",\n",
    "                  pipeline_root=PIPELINE_ROOT)\n",
    "def pipeline(\n",
    "    #bq_source: str = \"bq://aju-dev-demos.beans.beans1\",\n",
    "    display_name: str = DISPLAY_NAME,\n",
    "    project: str = PROJECT_ID,\n",
    "    gcp_region: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    thresholds_dict_str: str = '{\"auRoc\": 0.95}',\n",
    "):\n",
    "#     dataset_create_op = gcc_aip.TabularDatasetCreateOp(\n",
    "#         project=project, display_name=display_name, bq_source=bq_source\n",
    "#     )\n",
    "    \n",
    "    #dataset_op = get_data()\n",
    "    \n",
    "    create_dataset = gcc_aip.TabularDatasetCreateOp(\n",
    "    project=project,\n",
    "    display_name=display_name,\n",
    "    gcs_source=\"gs://pipelinetest_testing/iris.csv\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    training_op = gcc_aip.AutoMLTabularTrainingJobRunOp(\n",
    "        project=project,\n",
    "        display_name=display_name,\n",
    "        optimization_prediction_type=\"classification\",\n",
    "        budget_milli_node_hours=1,\n",
    "        dataset=create_dataset.outputs[\"dataset\"],\n",
    "        target_column=\"target\",\n",
    "    )\n",
    "    model_eval_task = classif_model_eval_metrics(\n",
    "        project,\n",
    "        gcp_region,\n",
    "        api_endpoint,\n",
    "        thresholds_dict_str,\n",
    "        training_op.outputs[\"model\"],\n",
    "    )\n",
    "\n",
    "    with dsl.Condition(\n",
    "        model_eval_task.outputs[\"dep_decision\"] == \"true\",\n",
    "        name=\"deploy_decision\",\n",
    "    ):\n",
    "\n",
    "        deploy_op = gcc_aip.ModelDeployOp(  # noqa: F841\n",
    "            model=training_op.outputs[\"model\"],\n",
    "            project=project,\n",
    "            machine_type=\"n1-standard-4\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "579c22d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "        package_path='cancer_pipe.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ac800455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/pipeline-test-1-20210802145335?project=pipelinetest-321606\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "api_client = AIPlatformClient(\n",
    "                project_id=PROJECT_ID,\n",
    "                region=REGION\n",
    "                )\n",
    "\n",
    "response = api_client.create_run_from_job_spec(\n",
    "    'cancer_pipe.json',\n",
    "    enable_caching= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEDULE = '30 5 * * *'\n",
    "TIME_ZONE = \"Asia/Calcutta\"\n",
    "\n",
    "api_client.create_schedule_from_job_spec(\n",
    "    job_spec_path=COMPILED_PIPELINE_PATH,\n",
    "    schedule=SCHEDULE,\n",
    "    time_zone=TIME_ZONE,\n",
    "    # parameter_values=PIPELINE_PARAMETERS\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
